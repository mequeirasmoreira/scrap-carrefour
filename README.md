# Scraper do Carrefour

## Descri√ß√£o
Este projeto √© um web scraper para o site do Carrefour que coleta informa√ß√µes de produtos da se√ß√£o de bebidas. Ele utiliza Puppeteer para automatizar a navega√ß√£o no site e extrair dados como t√≠tulo, pre√ßo e link dos produtos.

## Funcionalidades
- Navega√ß√£o automatizada no site do Carrefour
- Configura√ß√£o de CEP para simular localiza√ß√£o espec√≠fica
- Coleta de informa√ß√µes de produtos (t√≠tulo, pre√ßo, link)
- Gera√ß√£o de ID √∫nico para cada produto
- Pagina√ß√£o autom√°tica para coletar produtos de m√∫ltiplas p√°ginas
- Salvamento dos dados em formato JSON

Os dados coletados ser√£o salvos em `output.json` e as estat√≠sticas em `stats.json`.

## Configura√ß√£o
Voc√™ pode modificar as seguintes vari√°veis no in√≠cio do arquivo `index.js`:
- `url`: URL da p√°gina de produtos a ser raspada
- `cep`: CEP a ser utilizado para definir a localiza√ß√£o

## Dificuldades encontradas
- O bot√£o de busca por CEP poderia ter vindo com cache via localStorage, por isso optei por n√£o manter uma inst√¢ncia permanente no navegador.
- O bot√£o de inserir o CEP √©, na verdade, uma div contendo um button, o que gerou confus√£o ao tentar buscar diretamente pela tag <button>. Acabei recorrendo √† alternativa via CSS, utilizando os seletores que o fs oferece para manipula√ß√£o do DOM.
- Existe um bot√£o de chat que utiliza os mesmos seletores CSS do bot√£o de localizar o CEP. Por isso, precisei interceptar esse evento no carregamento da √°rvore DOM (DOMContentLoaded) e remover a inst√¢ncia duplicada.
- Para resolver esses tr√™s problemas, precisei aguardar as conex√µes da p√°gina serem tratadas corretamente. Foi a√≠ que descobri o networkidle2, j√° que eu estava acostumado apenas com o networkidle0. O networkidle2 se mostrou mais eficaz, principalmente em p√°ginas com Next.js, pois evita interrup√ß√µes nas conex√µes e permite validar os itens com mais precis√£o em intervalos de tempo.
- Meu dispositivo tem uma tela grande, o que alterava o viewport e, consequentemente, mudava a configura√ß√£o dos elementos via CSS. Isso gerava inconsist√™ncias no posicionamento dos componentes. Mais √† frente vou detalhar melhor esse ponto, mas a solu√ß√£o foi for√ßar o viewport manualmente para evitar que a estrutura do c√≥digo quebrasse.
- Alguns produtos apresentavam dois pre√ßos (antes e depois do desconto) com os mesmos seletores, diferenciando-se apenas pela cor do texto. Como o site usa Tailwind, isso facilitou bastante: consegui manipular o DOM usando seletores gen√©ricos por√©m precisos, sem perder o foco no elemento correto.
- O grid de produtos inclu√≠a itens patrocinados, o que causava duplicidade. Isso fez com que o n√∫mero de produtos informados na tag de contagem fosse diferente da quantidade real renderizada por p√°gina. A l√≥gica da renderiza√ß√£o era algo como:
```
n√∫mero total informado na p√°gina = numElemPage
n√∫mero de itens renderizados por p√°gina = numIteRend
maior n√∫mero de p√°ginas na navega√ß√£o = maxNumPage

SE (maxNumPage * numIteRend) < numElemPage
‚Üí √∫ltima p√°gina ter√° menos itens

POR√âM...
Ao executar, o total de itens era maior do que o previsto, pois alguns produtos (ex: Red Bull Energy Drink) apareciam em mais de uma p√°gina.
```
- O que fiz com esse problema? Nada üòÖ. Como utilizamos um normalizador que verifica o link e o nome padronizado do item (No teste anterior), isso n√£o interferiu no resultado final.
- O tempo de execu√ß√£o para carregar uma p√°gina com 60 itens estava acima do ideal. Por isso, estabeleci um timeout de 5000ms para garantir que tudo fosse carregado com seguran√ßa antes de continuar o processo.
